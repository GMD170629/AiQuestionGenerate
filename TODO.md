# 📚 AI 计算机教材习题生成器 - 开发清单

## 🚀 第一阶段：基础环境与全栈框架搭建

* [x] **初始化项目结构**
* [x] 整体环境在docker中运行
* [x] 创建 `backend/` (FastAPI) 和 `frontend/` (Next.js/React) 目录。
* [x] 配置 Python 虚拟环境及依赖（`fastapi`, `uvicorn`, `python-multipart`, `pydantic`）。
* [x] 配置前端 `Tailwind CSS` 及基础 UI 组件库。


* [x] **文件上传通道**
* [x] 实现后端 `/upload` 接口，支持 Markdown 文件接收并存储至临时目录。
* [x] 前端实现拖拽上传组件（使用 `lucide-react` 图标）。


* [x] **文件管理功能**
* [x] 实现后端文件列表、查看、删除接口。
* [x] 前端实现文件管理组件，展示已上传文件列表。
* [x] 实现文件预览功能（支持 Markdown 渲染）。
* [x] 实现文件删除功能。



## 📖 第二阶段：Markdown 解析与文本预处理 (RAG 基础)

* [x] **深度解析引擎**
* [x] 解析 Markdown 文件，提取文本内容。
* [x] **核心逻辑**：使用 LangChain 的 MarkdownHeaderTextSplitter 按标题层级切分文档。
* [x] 保留代码块（包括语言标识符，如 ```python）。
* [x] 使用 RecursiveCharacterTextSplitter 进行二次切片，确保每个 Chunk 不超过 1200 字。
* [x] 保留标题元数据（章节名、层级）。


* [x] **文本切片逻辑**
* [x] 实现 `RecursiveCharacterTextSplitter`，按语义长度（如 1200 字）切分文档。
* [x] 为每个 Chunk 添加元数据（章节名、层级信息）。



## 🧠 第三阶段：LLM 提示词工程与生成逻辑

* [x] **LLM 集成**
* [x] 封装 OpenRouter API 调用模块。


* [x] **提示词模板设计**
* [x] **单选题模板**：基于上下文生成具有迷惑项的题目。
* [x] **多选题模板**： 2个或以上正确答案，避免"全对/全错"。
* [x] **判断题模板**： 陈述清晰，错误点明确。
* [x] **填空题模板**： 答案唯一，多空用【1】【2】编号。
* [x] **简答题模板**： 答案要分点给出，逻辑清晰。
* [x] **编程题模板**：选取教材示例代码，挖空关键逻辑，要求符合语法规范。


* [x] **结构化输出 (JSON)**
* [x] 定义 Pydantic 模型，强制 LLM 返回格式化数据（`question`, `options`, `answer`, `explanation`, `code_snippet`）。



## 🎨 第四阶段：前端交互与习题渲染

* [x] **题目展示列表**
* [x] 适配不同题型的卡片渲染。
* [x] 集成 `react-syntax-highlighter` 实现习题中代码块的高亮。


* [x] **交互功能**
* [x] "点击显示答案/解析"的切换逻辑。
* [x] 习题筛选功能（按题型、按文件）。
* [x] 题目库页面：查看所有已生成的题目，支持按文件和题型筛选。


* [x] **导出模块**
* [x] 实现 `Export to Markdown` 功能。



## 🛠 第五阶段：优化与鲁棒性

* [x] **流式传输 (Streaming)**
* [x] 优化生成体验，前端实时显示 AI 正在出题的状态。
* [x] 优化题目展示窗口，添加滚动和最大高度限制，解决窗口超出屏幕无法点击的问题。


* [x] **错误处理**
* [x] 处理 Markdown 文件格式错误。
* [x] 处理 LLM 输出 JSON 格式错误时的自动重试逻辑。

## 🏗 第六阶段：后台任务系统与持久化 (核心架构升级)
- [x] **数据库模型设计**
    - [x] 设计 `Textbook` 模型：管理教材目录及包含的 Markdown 文件。
    - [x] 设计 `GenerationTask` 模型：记录任务状态（等待中、执行中、已完成、失败）、总进度、当前文件。
    - [x] 设计 `Question` 持久化存储：将生成的题目关联至对应的文件和教材。
- [x] **异步任务处理 (Background Workers)**
    - [x] 集成 `FastAPI BackgroundTasks` 或 `Celery/Redis`（推荐简单起步用 BackgroundTasks）。
    - [x] 实现任务调度器：能够按顺序轮询教材下的所有 Markdown 文件，并调用第三阶段的生成逻辑。
- [x] **实时进度推送**
    - [x] 实现 `SSE (Server-Sent Events)` 接口，允许前端订阅任务进度更新。

## 📊 第七阶段：自动化全书出题逻辑
- [x] **智能出题策略优化**
    - [x] **自适应识别**：修改 `generator.py`，让 AI 先分析切片内容的密度，自主决定生成 3 道还是 10 道题，以及选择最适合该知识点的题型（如算法选编程题，概念选单选题）。
    - [ ] **令牌桶限流控制**：针对全书生成任务，添加频率限制（Rate Limiting）逻辑，防止触发 LLM API 的并发限制。（当前使用简单延迟，需要改进为令牌桶算法）
- [x] **批量处理流水线**
    - [x] 实现"教材级"遍历逻辑：读取文件夹 -> 过滤 MD 文件 -> 逐个文件切片 -> 逐个切片调用 AI -> 结果落库。

## 🖥 第八阶段：题目生成管理界面 (Frontend)
- [x] **任务中心页面**
    - [x] 开发教材选择器：支持选择已上传的教材文件夹。
    - [x] 实现任务启动按钮及"后台运行"提示。
- [x] **可视化进度条**
    - [x] 使用 `Radix UI` 或 `Shadcn UI` 的 Progress 组件展示总体进度。
    - [x] 展示详细日志流：如"正在处理：第二章 内存管理.md (75%)..."
- [x] **任务持久化查看**
    - [x] 实现任务列表页：即使用户刷新或关闭页面重进，也能从后端获取当前正在执行的任务状态。